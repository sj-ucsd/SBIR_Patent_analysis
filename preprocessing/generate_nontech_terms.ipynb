{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4c784db-4784-4d68-91b0-4bc7aefda5db",
   "metadata": {},
   "source": [
    "# Extract Non-technical terms\n",
    "Use a sample of 10k SBIR documents to extract non-technical terms. We basically do entity extraction from the 10k samples here. The SBIR document is in csv format and can be downlaoded from: https://www.sbir.gov/sbirsearch/award/all - We used \"with abstract data\" option to download. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bad0fa1-8368-4214-8ecf-86a36807860e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#import scispacy as scisp\n",
    "from nltk.corpus import stopwords\n",
    "from itertools import chain\n",
    "import import_ipynb   #PS comment pip install import-ipynb \n",
    "import spacy as sp  #PS !pip install spacy\n",
    "import nltk  # PS needs to be added\n",
    "import spacy # PS needs to be added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dbf5292-8aa2-46ad-9c57-d47eb60e794e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from spacy_helper_methods.ipynb\n"
     ]
    }
   ],
   "source": [
    "# Import spacy helper functions from the helper notebook\n",
    "\n",
    "#subdirectory = \"/Users/prakhar/Documents/work/ucsd/dse203/SBIR_Patent_analysis\"\n",
    "\n",
    "# PS spacy_helper_methods notebook should be in same directory\n",
    "\n",
    "import spacy_helper_methods as sph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d4c93b0-7327-478b-bba3-f47c9a10fe8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbir_df = pd.read_csv('../input_files/award_data.csv',usecols=['Abstract'])  # PS update the path location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b432f77-2e22-4468-ace3-86e8911ed3ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173500"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleanup\n",
    "sbir_df = sbir_df.dropna()\n",
    "len(sbir_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d55a07a0-00f7-41a4-a673-bcbd1cd916a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a sample of 10k abstracts to create non-tech words \n",
    "sbir_df = sbir_df.sample(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95ec8530-9ffe-49aa-b46e-75ac73e76039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71458</th>\n",
       "      <td>Currently, the Military lacks the capability t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192680</th>\n",
       "      <td>THE CONSTRAINTS OF REAL-TIME APPLICATIONS CANN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46593</th>\n",
       "      <td>The development of a low-cost permeable unidir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11359</th>\n",
       "      <td>Nitricity is developing a technology that prod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54781</th>\n",
       "      <td>Project Summary We aim to introduce to the hea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Abstract\n",
       "71458   Currently, the Military lacks the capability t...\n",
       "192680  THE CONSTRAINTS OF REAL-TIME APPLICATIONS CANN...\n",
       "46593   The development of a low-cost permeable unidir...\n",
       "11359   Nitricity is developing a technology that prod...\n",
       "54781   Project Summary We aim to introduce to the hea..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbir_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff0b9e29-a175-42af-b231-ecd0dac157fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/prakhar/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Remove stopwords using nltk. Initial parse seems to be faster than spacy and \n",
    "# doesn't seem to remove all stopwords compared to spacy hence after inital pass\n",
    "# will still filter on spacy's stopwords in lemmatize method\n",
    "\n",
    "nltk.download('stopwords')    # PS needs to be downloaded\n",
    "\n",
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7966ed2e-c7d7-4e70-9408-e965b3279f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.19 s, sys: 2.33 ms, total: 1.19 s\n",
      "Wall time: 1.19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sbir_df = sbir_df['Abstract'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07c3cdfa-ae6a-4196-9766-60394da19e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdaa2896-681c-42dc-90df-e24026ecf21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the scispacy large vocabulary - gives us lot more entities than spacy \n",
    "# note that sci spacy vocabulary was trained with spacy 3.6.1 hence may get warning\n",
    "\n",
    "nlp = sp.load(\"en_core_web_lg\")  #PS !python -m spacy download en_core_web_lg to be installed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9777ef6-bf7c-45bf-9db7-683baa778ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 24s, sys: 2.54 s, total: 4min 26s\n",
      "Wall time: 4min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load the scispacy large vocabulary. Lemmatization seems to be faster with this \n",
    "lemma_ds = sph.lemmatize(nlp, sbir_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d41df4a-5d6d-43e5-9d91-72527f4ce003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 4s, sys: 1.79 s, total: 4min 6s\n",
      "Wall time: 4min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ent_ds = sph.get_entities(nlp, lemma_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89a4b02c-d540-4250-af62-18225ce069e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collapse all tuples into a flat list\n",
    "tuple_list = list(set(list(chain.from_iterable(ent_ds.values))))\n",
    "tuple_list = [tuple for tuple in tuple_list if tuple[1] not in ['CARDINAL','PERCENT','TIME','QUANTITY','MONEY']]\n",
    "entities = list(set(list([i[0] for i in tuple_list])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c788a9c2-1993-4275-95fc-15815d469557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove any entities that are in the technical word list\n",
    "# load technical terms\n",
    "with open('../preprocessed_files/tech_terms.txt','r') as f:\n",
    "    text = f.read()\n",
    "techwords = text.split('\\n')\n",
    "ts = pd.Series(techwords).str.lower()\n",
    "ts.head()\n",
    "\n",
    "#convert entity list generated above from SBIR abstract to lower\n",
    "nts = pd.Series(entities).str.lower()\n",
    "\n",
    "#filter all technical words from nts\n",
    "nts = nts[~nts.isin(ts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f22a132d-6c72-4ed9-a009-28837b7be653",
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = [entity for entity in entities if entity.lower() in list(nts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9439b60c-1e35-4f64-aa4a-5125c826a7cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29976,\n",
       " ['Power Energy , Inc.',\n",
       "  'AL FEASIBILITY',\n",
       "  'UEOS',\n",
       "  'CalRAM Inc.',\n",
       "  'Air Vehicles Directorate'],\n",
       " [('NanoSpray Combustion', 'ORG'),\n",
       "  ('MAC', 'ORG'),\n",
       "  ('Field Scanning Optical Microscopy ( NSOM', 'ORG'),\n",
       "  ('commercializationpotential dod program', 'ORG'),\n",
       "  ('Oregon Health Science Uni', 'ORG')])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(entities), entities[:5], tuple_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40407f75-d0b1-47f9-89e2-c286d446636e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('non_tech.txt','w') as nf:\n",
    "    nf.writelines('\\n'.join(map(str, entities)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f3ce9a-ebcd-44b8-8b24-9dab36f4a234",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
