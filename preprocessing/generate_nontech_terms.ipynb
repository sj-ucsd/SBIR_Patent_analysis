{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4c784db-4784-4d68-91b0-4bc7aefda5db",
   "metadata": {},
   "source": [
    "# Extract Non-technical terms\n",
    "Use a sample of 10k SBIR documents to extract non-technical terms. We basically do entity extraction from the 10k samples here. The SBIR document is in csv format and can be downlaoded from: https://www.sbir.gov/sbirsearch/award/all - We used \"with abstract data\" option to download. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bad0fa1-8368-4214-8ecf-86a36807860e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#import scispacy as scisp\n",
    "from nltk.corpus import stopwords\n",
    "from itertools import chain\n",
    "import import_ipynb\n",
    "import spacy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dbf5292-8aa2-46ad-9c57-d47eb60e794e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from spacy_helper_methods.ipynb\n"
     ]
    }
   ],
   "source": [
    "# Import spacy helper functions from the helper notebook\n",
    "import spacy_helper_methods as sph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d4c93b0-7327-478b-bba3-f47c9a10fe8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbir_df = pd.read_csv('award_data.csv',usecols=['Abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b432f77-2e22-4468-ace3-86e8911ed3ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173501"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleanup\n",
    "sbir_df = sbir_df.dropna()\n",
    "len(sbir_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d55a07a0-00f7-41a4-a673-bcbd1cd916a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a sample of 10k abstracts to create non-tech words \n",
    "sbir_df = sbir_df.sample(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95ec8530-9ffe-49aa-b46e-75ac73e76039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16366</th>\n",
       "      <td>Freedom Photonics proposes to develop a pressu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50432</th>\n",
       "      <td>The broader impact/commercial potential of thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100717</th>\n",
       "      <td>The objective of this proposal is to improve t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12093</th>\n",
       "      <td>Global economic impact of pathogenic plant vir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113174</th>\n",
       "      <td>The versatility of military fixed and rotary w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Abstract\n",
       "16366   Freedom Photonics proposes to develop a pressu...\n",
       "50432   The broader impact/commercial potential of thi...\n",
       "100717  The objective of this proposal is to improve t...\n",
       "12093   Global economic impact of pathogenic plant vir...\n",
       "113174  The versatility of military fixed and rotary w..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbir_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff0b9e29-a175-42af-b231-ecd0dac157fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stopwords using nltk. Initial parse seems to be faster than spacy and \n",
    "# doesn't seem to remove all stopwords compared to spacy hence after inital pass\n",
    "# will still filter on spacy's stopwords in lemmatize method\n",
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7966ed2e-c7d7-4e70-9408-e965b3279f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.1 s, sys: 76.6 ms, total: 6.18 s\n",
      "Wall time: 6.52 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sbir_df = sbir_df['Abstract'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c3cdfa-ae6a-4196-9766-60394da19e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdaa2896-681c-42dc-90df-e24026ecf21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the scispacy large vocabulary - gives us lot more entities than spacy \n",
    "# note that sci spacy vocabulary was trained with spacy 3.6.1 hence may get warning\n",
    "nlp = sp.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9777ef6-bf7c-45bf-9db7-683baa778ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 8s, sys: 46.1 s, total: 7min 54s\n",
      "Wall time: 9min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load the scispacy large vocabulary. Lemmatization seems to be faster with this \n",
    "lemma_ds = sph.lemmatize(nlp, sbir_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d41df4a-5d6d-43e5-9d91-72527f4ce003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min, sys: 36.7 s, total: 6min 36s\n",
      "Wall time: 7min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ent_ds = sph.get_entities(nlp, lemma_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "89a4b02c-d540-4250-af62-18225ce069e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collapse all tuples into a flat list\n",
    "tuple_list = list(set(list(chain.from_iterable(ent_ds.values))))\n",
    "tuple_list = [tuple for tuple in tuple_list if tuple[1] not in ['CARDINAL','PERCENT','TIME','QUANTITY','MONEY']]\n",
    "entities = list(set(list([i[0] for i in tuple_list])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c788a9c2-1993-4275-95fc-15815d469557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove any entities that are in the technical word list\n",
    "# load technical terms\n",
    "with open('tech.txt','r') as f:\n",
    "    text = f.read()\n",
    "techwords = text.split('\\n')\n",
    "ts = pd.Series(techwords).str.lower()\n",
    "ts.head()\n",
    "\n",
    "#convert entity list generated above from SBIR abstract to lower\n",
    "nts = pd.Series(entities).str.lower()\n",
    "\n",
    "#filter all technical words from nts\n",
    "nts = nts[~nts.isin(ts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f22a132d-6c72-4ed9-a009-28837b7be653",
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = [entity for entity in entities if entity.lower() in list(nts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9439b60c-1e35-4f64-aa4a-5125c826a7cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30377,\n",
       " ['allowteacher',\n",
       "  'Eltron',\n",
       "  'MAJOR MEDICAL SUPPLY COMPANY',\n",
       "  'MORBIDITY MORTALITY',\n",
       "  'Ocean Observing'],\n",
       " [('TUMORS 3', 'ORG'),\n",
       "  ('tertiary', 'ORDINAL'),\n",
       "  ('DETECTORS', 'PRODUCT'),\n",
       "  ('ISAV', 'ORG'),\n",
       "  ('ac / dc load bank', 'ORG')])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(entities), entities[:5], tuple_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "40407f75-d0b1-47f9-89e2-c286d446636e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('non_tech.txt','w') as nf:\n",
    "    nf.writelines('\\n'.join(map(str, entities)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
